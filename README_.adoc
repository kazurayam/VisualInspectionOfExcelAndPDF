= Visual Inspection of Excel and PDF

== Motivation

A few years ago, I worked for a media company in Tokyo. I was asked to develop a tool software, which is a sort of web scraping tool. The target page is https://www.fsa.go.jp/policy/nisa2/about/tsumitate/target/index.html[this], which is still available to public at MAR 2022. The page looks something like this:

image:./docs/images/01_NISA_target_page.png[alt=target,width=640]

You don't have to understand this page in detail except the following points.

1. The page contains several `<a href="...">` tags to the URLs of Excel files and PDF files.
2. The URL string of Excel/PDF files are fixed. The file names are fixed. The URLs are not variable.
3. The content of Excel & PDF files are updated by the publisher irregularly. The frequency of updates are not determined. You can track the record: once a month, or once per 2 months.
4. The publisher does not provide any push-style notification (like https://en.wikipedia.org/wiki/RSS[RSS]) for this page. Those who are interested in the information of this page are asked to keep watching the page, read it and find updates.
5. The company I worked for had a serious interest in the Excel files. Therefore some staffs are asked to visit this page everyday.
6. The staffs hated this job. No need to tell why. They wanted some system to automate this _bullshit job_.

== Problem to solve

== Solution

== Description

== Demonstration

